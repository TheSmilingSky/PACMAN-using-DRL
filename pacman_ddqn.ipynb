{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "pacman-ddqn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4203506e",
        "outputId": "84b0375f-2f29-4c25-f551-b282bc298461"
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    %tensorflow_version 2.x\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "if COLAB:\n",
        "  !sudo apt-get install -y xvfb ffmpeg\n",
        "  !pip install -q 'gym==0.10.11'\n",
        "  !pip install -q 'imageio==2.4.0'\n",
        "  !pip install -q PILLOW\n",
        "  !pip install -q 'pyglet==1.3.2'\n",
        "  !pip install -q pyvirtualdisplay\n",
        "  !pip install -q --upgrade tensorflow-probability\n",
        "  !pip install -q tf-agents\n",
        "\n",
        "  # ROM dependencies for atari games\n",
        "  ! wget http://www.atarimania.com/roms/Roms.rar\n",
        "  ! mkdir /content/ROM/\n",
        "  ! unrar e /content/Roms.rar /content/ROM/\n",
        "  ! python -m atari_py.import_roms /content/ROM/\n",
        "\n",
        "  # For visualisation on colab\n",
        "  !pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "  !apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "\n",
        "  # gym installation\n",
        "  !apt-get update > /dev/null 2>&1\n",
        "  !apt-get install cmake > /dev/null 2>&1\n",
        "  !pip install --upgrade setuptools 2>&1\n",
        "  !pip install ez_setup > /dev/null 2>&1\n",
        "  !pip install gym[atari] > /dev/null 2>&1\n",
        "\n",
        "  # For use of GPU\n",
        "  %tensorflow_version 2.x\n",
        "  import tensorflow as tf\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "  if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "    global CPU\n",
        "    CPU = True\n",
        "  print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "  # Required to save models in HDF5 format\n",
        "  !pip install pyyaml h5py"
      ],
      "id": "4203506e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: using Google CoLab\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 59 not upgraded.\n",
            "\u001b[31mERROR: tf-agents 0.8.0 has requirement gym>=0.17.0, but you'll have gym 0.10.11 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tf-agents 0.8.0 has requirement gym>=0.17.0, but you'll have gym 0.10.11 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tf-agents 0.8.0 has requirement tensorflow-probability==0.12.2, but you'll have tensorflow-probability 0.13.0 which is incompatible.\u001b[0m\n",
            "--2021-07-15 11:01:01--  http://www.atarimania.com/roms/Roms.rar\n",
            "Resolving www.atarimania.com (www.atarimania.com)... 195.154.81.199\n",
            "Connecting to www.atarimania.com (www.atarimania.com)|195.154.81.199|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11128004 (11M) [application/x-rar-compressed]\n",
            "Saving to: ‘Roms.rar.2’\n",
            "\n",
            "Roms.rar.2          100%[===================>]  10.61M   821KB/s    in 14s     \n",
            "\n",
            "2021-07-15 11:01:15 (792 KB/s) - ‘Roms.rar.2’ saved [11128004/11128004]\n",
            "\n",
            "mkdir: cannot create directory ‘/content/ROM/’: File exists\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/Roms.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file /content/ROM/HC ROMS.zip\n",
            "11826711 bytes, modified on 2019-12-22 11:24\n",
            "with a new one\n",
            "11826711 bytes, modified on 2019-12-22 11:24\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c00cd5f3",
        "outputId": "d8770651-8734-4931-9a6a-39ddb07036fe"
      },
      "source": [
        ""
      ],
      "id": "c00cd5f3",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-15 09:36:35--  http://www.atarimania.com/roms/Roms.rar\n",
            "Resolving www.atarimania.com (www.atarimania.com)... 195.154.81.199\n",
            "Connecting to www.atarimania.com (www.atarimania.com)|195.154.81.199|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11128004 (11M) [application/x-rar-compressed]\n",
            "Saving to: ‘Roms.rar’\n",
            "\n",
            "Roms.rar            100%[===================>]  10.61M   836KB/s    in 13s     \n",
            "\n",
            "2021-07-15 09:36:48 (807 KB/s) - ‘Roms.rar’ saved [11128004/11128004]\n",
            "\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/Roms.rar\n",
            "\n",
            "Extracting  /content/ROM/HC ROMS.zip                                     \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  /content/ROM/ROMS.zip                                        \b\b\b\b 74%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "copying adventure.bin from ROMS/Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/adventure.bin\n",
            "copying air_raid.bin from ROMS/Air Raid (Men-A-Vision) (PAL) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/air_raid.bin\n",
            "copying alien.bin from ROMS/Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/alien.bin\n",
            "copying amidar.bin from ROMS/Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/amidar.bin\n",
            "copying assault.bin from ROMS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/assault.bin\n",
            "copying asterix.bin from ROMS/Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asterix.bin\n",
            "copying asteroids.bin from ROMS/Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asteroids.bin\n",
            "copying atlantis.bin from ROMS/Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/atlantis.bin\n",
            "copying bank_heist.bin from ROMS/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bank_heist.bin\n",
            "copying battle_zone.bin from ROMS/Battlezone (1983) (Atari - GCC, Mike Feinstein, Brad Rice) (CX2681) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/battle_zone.bin\n",
            "copying beam_rider.bin from ROMS/Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/beam_rider.bin\n",
            "copying berzerk.bin from ROMS/Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/berzerk.bin\n",
            "copying bowling.bin from ROMS/Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bowling.bin\n",
            "copying boxing.bin from ROMS/Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/boxing.bin\n",
            "copying breakout.bin from ROMS/Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/breakout.bin\n",
            "copying carnival.bin from ROMS/Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/carnival.bin\n",
            "copying centipede.bin from ROMS/Centipede (1983) (Atari - GCC) (CX2676) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/centipede.bin\n",
            "copying chopper_command.bin from ROMS/Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/chopper_command.bin\n",
            "copying crazy_climber.bin from ROMS/Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/crazy_climber.bin\n",
            "copying defender.bin from ROMS/Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/defender.bin\n",
            "copying demon_attack.bin from ROMS/Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/demon_attack.bin\n",
            "copying donkey_kong.bin from ROMS/Donkey Kong (1982) (Coleco - Woodside Design Associates - Imaginative Systems Software, Garry Kitchen) (2451) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/donkey_kong.bin\n",
            "copying double_dunk.bin from ROMS/Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/double_dunk.bin\n",
            "copying elevator_action.bin from ROMS/Elevator Action (1983) (Atari, Dan Hitchens) (CX26126) (Prototype) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/elevator_action.bin\n",
            "copying enduro.bin from ROMS/Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/enduro.bin\n",
            "copying fishing_derby.bin from ROMS/Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/fishing_derby.bin\n",
            "copying freeway.bin from ROMS/Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/freeway.bin\n",
            "copying frogger.bin from ROMS/Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frogger.bin\n",
            "copying frostbite.bin from ROMS/Frostbite (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frostbite.bin\n",
            "copying galaxian.bin from ROMS/Galaxian (1983) (Atari - GCC, Mark Ackerman, Tom Calderwood, Glenn Parker) (CX2684) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/galaxian.bin\n",
            "copying gopher.bin from ROMS/Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gopher.bin\n",
            "copying gravitar.bin from ROMS/Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gravitar.bin\n",
            "copying hero.bin from ROMS/H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/hero.bin\n",
            "copying ice_hockey.bin from ROMS/Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ice_hockey.bin\n",
            "copying jamesbond.bin from ROMS/James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Louis Marbel) (PB5110) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/jamesbond.bin\n",
            "copying journey_escape.bin from ROMS/Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/journey_escape.bin\n",
            "copying kaboom.bin from ROMS/Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, AG-010-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kaboom.bin\n",
            "copying kangaroo.bin from ROMS/Kangaroo (1983) (Atari - GCC, Kevin Osborn) (CX2689) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kangaroo.bin\n",
            "copying keystone_kapers.bin from ROMS/Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/keystone_kapers.bin\n",
            "copying king_kong.bin from ROMS/King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/king_kong.bin\n",
            "copying koolaid.bin from ROMS/Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/koolaid.bin\n",
            "copying krull.bin from ROMS/Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/krull.bin\n",
            "copying kung_fu_master.bin from ROMS/Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kung_fu_master.bin\n",
            "copying laser_gates.bin from ROMS/Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/laser_gates.bin\n",
            "copying lost_luggage.bin from ROMS/Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/lost_luggage.bin\n",
            "copying montezuma_revenge.bin from ROMS/Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
            "copying mr_do.bin from ROMS/Mr. Do! (1983) (CBS Electronics, Ed English) (4L4478) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/mr_do.bin\n",
            "copying ms_pacman.bin from ROMS/Ms. Pac-Man (1983) (Atari - GCC, Mark Ackerman, Glenn Parker) (CX2675) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ms_pacman.bin\n",
            "copying name_this_game.bin from ROMS/Name This Game (Guardians of Treasure) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/name_this_game.bin\n",
            "copying pacman.bin from ROMS/Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pacman.bin\n",
            "copying phoenix.bin from ROMS/Phoenix (1983) (Atari - GCC, Mike Feinstein, John Mracek) (CX2673) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/phoenix.bin\n",
            "copying video_pinball.bin from ROMS/Pinball (AKA Video Pinball) (Zellers).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/video_pinball.bin\n",
            "copying pitfall.bin from ROMS/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pitfall.bin\n",
            "copying pooyan.bin from ROMS/Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pooyan.bin\n",
            "copying private_eye.bin from ROMS/Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/private_eye.bin\n",
            "copying qbert.bin from ROMS/Q-bert (1983) (Parker Brothers - Western Technologies, Dave Hampton, Tom Sloper) (PB5360) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/qbert.bin\n",
            "copying riverraid.bin from ROMS/River Raid (1982) (Activision, Carol Shaw) (AX-020, AX-020-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/riverraid.bin\n",
            "copying road_runner.bin from patched version of ROMS/Road Runner (1989) (Atari - Bobco, Robert C. Polaro) (CX2663) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/road_runner.bin\n",
            "copying robotank.bin from ROMS/Robot Tank (Robotank) (1983) (Activision, Alan Miller) (AZ-028, AG-028-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/robotank.bin\n",
            "copying seaquest.bin from ROMS/Seaquest (1983) (Activision, Steve Cartwright) (AX-022) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/seaquest.bin\n",
            "copying sir_lancelot.bin from ROMS/Sir Lancelot (1983) (Xonox - K-Tel Software - Product Guild, Anthony R. Henderson) (99006, 6220) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/sir_lancelot.bin\n",
            "copying skiing.bin from ROMS/Skiing - Le Ski (1980) (Activision, Bob Whitehead) (AG-005, CAG-005, AG-005-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/skiing.bin\n",
            "copying solaris.bin from ROMS/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986) (Atari, Douglas Neubauer, Mimi Nyden) (CX26136) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/solaris.bin\n",
            "copying space_invaders.bin from ROMS/Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/space_invaders.bin\n",
            "copying star_gunner.bin from ROMS/Stargunner (1983) (Telesys, Alex Leavens) (1005) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/star_gunner.bin\n",
            "copying surround.bin from ROMS/Surround (32 in 1) (Bit Corporation) (R320).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/surround.bin\n",
            "copying tennis.bin from ROMS/Tennis - Le Tennis (1981) (Activision, Alan Miller) (AG-007, CAG-007) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tennis.bin\n",
            "copying time_pilot.bin from ROMS/Time Pilot (1983) (Coleco - Woodside Design Associates, Harley H. Puthuff Jr.) (2663) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/time_pilot.bin\n",
            "copying trondead.bin from ROMS/TRON - Deadly Discs (TRON Joystick) (1983) (M Network - INTV - APh Technological Consulting, Jeff Ronne, Brett Stutz) (MT5662) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/trondead.bin\n",
            "copying tutankham.bin from ROMS/Tutankham (1983) (Parker Brothers, Dave Engman, Dawn Stockbridge) (PB5340) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tutankham.bin\n",
            "copying up_n_down.bin from ROMS/Up 'n Down (1984) (SEGA - Beck-Tech, Steve Beck, Phat Ho) (009-01) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/up_n_down.bin\n",
            "copying venture.bin from ROMS/Venture (1982) (Coleco, Joseph Biel) (2457) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/venture.bin\n",
            "copying pong.bin from ROMS/Video Olympics - Pong Sports (Paddle) (1977) (Atari, Joe Decuir - Sears) (CX2621 - 99806, 6-99806, 49-75104) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pong.bin\n",
            "copying wizard_of_wor.bin from ROMS/Wizard of Wor (1982) (CBS Electronics - Roklan, Joe Hellesen, Joe Wagner) (M8774, M8794) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/wizard_of_wor.bin\n",
            "copying yars_revenge.bin from ROMS/Yars' Revenge (Time Freeze) (1982) (Atari, Howard Scott Warshaw - Sears) (CX2655 - 49-75167) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/yars_revenge.bin\n",
            "copying zaxxon.bin from ROMS/Zaxxon (1983) (Coleco) (2454) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/zaxxon.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8hk7mSYD6-Z"
      },
      "source": [
        ""
      ],
      "id": "t8hk7mSYD6-Z",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYPslwRpEBi8",
        "outputId": "e83a66eb-bee6-47cd-c63c-f21f754b1ab9"
      },
      "source": [
        ""
      ],
      "id": "HYPslwRpEBi8",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.7/dist-packages (57.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "TtevFJxvGSNm",
        "outputId": "e2c5794b-f3c0-4e11-cdb4-eb4a20ce5880"
      },
      "source": [
        ""
      ],
      "id": "TtevFJxvGSNm",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-d1d5f2f639c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Wa-iUJGZwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90aaf6d-daed-4920-f0a1-06963275d309"
      },
      "source": [
        ""
      ],
      "id": "32Wa-iUJGZwe",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5; python_version == \"3.7\" in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ioqp7yRmEEpU"
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "from google.colab import files,drive\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment \n",
        "and displaying it.\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  files.download(mp4list[0])\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    print(video)\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "id": "Ioqp7yRmEEpU",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cnPPyY_EG6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "6830a54a-9cc5-442e-918c-b127bd5ee87c"
      },
      "source": [
        "# env = wrap_env(gym.make(\"MountainCar-v0\"))\n",
        "# with tf.device('/device:GPU:0'):   \n",
        "\n",
        "for i in range(3):\n",
        "  env = wrap_env(gym.make(\"MsPacman-v0\")) \n",
        "  observation = env.reset()\n",
        "  while True:\n",
        "        \n",
        "        # env.render()\n",
        "        #your agent goes here\n",
        "        action = env.action_space.sample() \n",
        "        if(i==1): action = env.action_space.sample()\n",
        "\n",
        "        observation, reward, done, info = env.step(action)    \n",
        "            \n",
        "        if done:\n",
        "            env.close()\n",
        "            show_video()\n",
        "            break;\n",
        "\n",
        "# show_video()"
      ],
      "id": "6cnPPyY_EG6x",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-96-8aa0dda94e06>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTD9EeUYrfBt"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "id": "iTD9EeUYrfBt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51356073"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gym\n",
        "import scipy.misc\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "from skimage import transform\n",
        "from google.colab import files,drive\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras.losses import MeanSquaredError \n",
        "from tensorflow.keras.metrics import MeanSquaredError\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n"
      ],
      "id": "51356073",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a4203a0"
      },
      "source": [
        "env = wrap_env(gym.make('MsPacman-v0'))\n",
        "observation = env.reset()\n",
        "# input_shape = preprocess_observation(observation).shape\n",
        "input_shape = observation.shape\n",
        "classes = env.action_space.n\n",
        "env.close()\n",
        "# print(input_shape, classes)"
      ],
      "id": "7a4203a0",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0df84790"
      },
      "source": [
        "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    \n",
        "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "id": "0df84790",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cbd5f7b"
      },
      "source": [
        "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    \n",
        "    # First component of main path glorot_uniform(seed=0)\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    \n",
        "    ##### SHORTCUT PATH ##### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s,s), padding = 'valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training = training) # Default axis\n",
        "    \n",
        "    # Final step: \n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "id": "9cbd5f7b",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7fec656"
      },
      "source": [
        "def ResNet50(input_shape, classes): # input and classes depends on gym environment\n",
        "    \"\"\"\n",
        "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    \n",
        "    ## Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    X = identity_block(X, 3, [128, 128, 512]) \n",
        "    \n",
        "    ## Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "\n",
        "    ## Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "\n",
        "    ## AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D(pool_size = (2,2))(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "\n",
        "    return model"
      ],
      "id": "a7fec656",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b379db3a"
      },
      "source": [
        "def Deepminds_model(input_shape, classes):\n",
        "        \n",
        "        \n",
        "    X_input = Input(input_shape)\n",
        "    \n",
        "    X = Conv2D(32, (8, 8), strides = (4, 4), kernel_initializer = glorot_uniform(seed=0))(X_input)\n",
        "    X = Activation('relu')(X)\n",
        "    X = Conv2D(64, (4, 4), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = Conv2D(64, (3, 3), strides = (1, 1), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation='relu', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "\n",
        "    return model\n",
        "    \n",
        "    "
      ],
      "id": "b379db3a",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaa8e053"
      },
      "source": [
        ""
      ],
      "id": "eaa8e053",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54dd6a46"
      },
      "source": [
        "def scale_lumininance(img):\n",
        "    return np.dot(img[...,:3],[0.299,0.587,0.114])"
      ],
      "id": "54dd6a46",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b86ff3b"
      },
      "source": [
        "def preprocess_observation(obs):\n",
        "    \"\"\"\n",
        "    To reduce the computation load we preprocess the date obtained from the atari-game env by\n",
        "    reducing the resolution and adjusting the color.\n",
        "    \n",
        "    DeepMind took the maximum pixel value over subsequent frames to reduce flickering\n",
        "    caused by the limitations of the Atari platform and then scale it from its current \n",
        "    210×160×3 resolution to 84×84.\n",
        "    \n",
        "    To convert this, we will take the luminance channel (denoted as Y) from the image, which is the our RGB channel, and apply linear weights to \n",
        "    the channel to transform it according to the relative luminance.\n",
        "    Y = 0.299R + 0.587G + 0.114B\n",
        "    \"\"\"\n",
        "    \n",
        "    obs_gray = scale_lumininance(obs)\n",
        "    obs_trans = transform.resize(obs_gray,(84,84))\n",
        "    return np.moveaxis(obs_trans, 1, 0)"
      ],
      "id": "6b86ff3b",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1b15339"
      },
      "source": [
        "def initialization(input_shape , classes, initial_collect_steps, buffer_size):\n",
        "    \"\"\"\n",
        "    The target_network and prediction_network are initialized as ResNet50/DeepMind's CNN architecture with trainability\n",
        "    of prediction_network set to False.\n",
        "    \n",
        "    The Experience Reply is initialized as a deque whose each element \n",
        "    is a tuple (current state, action, reward , done, next state)\n",
        "    Few actions are executed with the environment to bootstrap the replay data.\n",
        "    \"\"\"\n",
        "    global target_network,prediction_network,experience_replay\n",
        "#     target_network = ResNet50(input_shape,classes)\n",
        "    target_network = Deepminds_model(input_shape,classes)  \n",
        "    # print(target_network.summary())\n",
        "    \n",
        "#     prediction_network = ResNet50(input_shape,classes)\n",
        "    prediction_network = Deepminds_model(input_shape,classes)\n",
        "    # print(prediction_network.summary())\n",
        "    \n",
        "    experience_replay = deque(maxlen = buffer_size)\n",
        "    \n",
        "    observation = env.reset()\n",
        "    for i in range(initial_collect_steps):\n",
        "        \n",
        "        # current_state = preprocess_observation(observation)\n",
        "        current_state = observation\n",
        "        action = env.action_space.sample()\n",
        "        observation, reward, done , _ = env.step(action)\n",
        "        # next_state = preprocess_observation(observation)\n",
        "        next_state = observation\n",
        "        # print(i)\n",
        "\n",
        "        if done:\n",
        "          observation = env.reset()\n",
        "        \n",
        "        sample_observation = (current_state,action,reward,done,next_state)\n",
        "        experience_replay.append(sample_observation)\n",
        "    env.close()"
      ],
      "id": "a1b15339",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1da5cd81"
      },
      "source": [
        "def plot(CR , episode, save_fig = True):\n",
        "    plt.plot([i+1 for i in range(episode)],CR, linewidth=4, label = \"DDQN\")\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"episode_reward\")\n",
        "    leg = plt.legend(loc='upper left', shadow=True)\n",
        "    plt.grid()\n",
        "    ax = plt.gca()\n",
        "    plt.xlim([0, episode])\n",
        "    \n",
        "    output_dir = os.path.join(os.getcwd(), \"output\")\n",
        "    if not os.path.exists(output_dir): os.mkdir(output_dir)\n",
        "    \n",
        "    if save_fig:\n",
        "        plt.savefig(os.path.join(output_dir, \"plot-{}th-episode.png\".format(episode)), bbox_inches=\"tight\")\n",
        "        files.download(os.path.join(output_dir, \"plot-{}th-episode.png\".format(episode)))\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()"
      ],
      "id": "1da5cd81",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d490d86"
      },
      "source": [
        "def eps_greedy_action(Q,eps):\n",
        "    if np.random.random() < eps: # explore\n",
        "        return np.random.randint(env.action_space.n)\n",
        "    else: # exploit\n",
        "        return np.random.choice(np.flatnonzero(Q == Q.numpy().max()))"
      ],
      "id": "2d490d86",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVVRnBdg8wn7"
      },
      "source": [
        "# @tf.function\n",
        "# def train_step(state_minibatch,target,actions):\n",
        "\n",
        "    "
      ],
      "id": "bVVRnBdg8wn7",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "771b5d7a"
      },
      "source": [
        "def experiment(N_episodes,gamma,learning_rate, c, batch_size,eps, log_interval):\n",
        "    \n",
        "  # Instantiate an optimizer to train the model.\n",
        "  optimizer = tf.keras.optimizers.RMSprop(learning_rate) # used by deepminds\n",
        "  # Instantiate a loss function.\n",
        "  loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "  # Prepare the metrics.\n",
        "  train_acc_metric = tf.keras.metrics.MeanSquaredError()\n",
        "  \n",
        "  CR = []\n",
        "  with tf.device('/device:GPU:0'):\n",
        "\n",
        "    for episode in range(N_episodes):\n",
        "        start_time = time.time()\n",
        "        time_step = 0\n",
        "        env = wrap_env(gym.make('MsPacman-v0'))\n",
        "        observation = env.reset()\n",
        "        rewards = [] # compared to total points earned in the game\n",
        "        while True:\n",
        "            \n",
        "            with tf.GradientTape() as tape:\n",
        "                \n",
        "                current_state = observation\n",
        "                # current_state = preprocess_observation(observation) \n",
        "                Q = prediction_network(np.array([current_state]), training=False)\n",
        "                action = eps_greedy_action(Q,eps) \n",
        "                new_observation , reward , done , _ = env.step(action)\n",
        "                rewards.append(reward)\n",
        "                next_state = new_observation\n",
        "                # next_state = preprocess_observation(new_observation)\n",
        "                \n",
        "                sample_observation = (current_state, action, reward, done, next_state)\n",
        "                experience_replay.append(sample_observation)\n",
        "                \n",
        "                minibatch = random.sample(list(experience_replay),batch_size)\n",
        "                state_minibatch = np.array([current_state for (current_state, action, reward, done, next_state) in minibatch])\n",
        "                actions = np.array([action for (current_state, action, reward, done, next_state) in minibatch])\n",
        "                            \n",
        "                target = []\n",
        "                for (current_state, action, reward, done, next_state) in minibatch:\n",
        "                    if done:\n",
        "                        target.append(reward)\n",
        "                    else:\n",
        "                        Q_target = target_network(np.array([next_state]),training = False)\n",
        "                        target.append(reward + gamma * Q_target.numpy().max())\n",
        "\n",
        "                prediction_network_output = prediction_network(state_minibatch, training = True)\n",
        "                prediction = [Q[action] for Q,action in zip(prediction_network_output,actions)]\n",
        "                \n",
        "                loss_value = loss_fn(target , prediction)\n",
        "                grads = tape.gradient(loss_value, prediction_network.trainable_variables)\n",
        "                optimizer.apply_gradients(zip(grads, prediction_network.trainable_variables))\n",
        "                \n",
        "                # Update training metric.\n",
        "                train_acc_metric.update_state(target, prediction)\n",
        "\n",
        "                # S -> S'\n",
        "                observation = new_observation\n",
        "                time_step+=1\n",
        "                if time_step%100 == 0 :\n",
        "                  print(\"Time_step:{}\".format(time_step))\n",
        "                \n",
        "                if episode%c ==0: \n",
        "                    target_network.set_weights(prediction_network.get_weights()) \n",
        "              \n",
        "                if done:\n",
        "                \n",
        "                    # Display metrics at the end of each episode.\n",
        "                    train_acc = train_acc_metric.result()\n",
        "                    print(\"Training acc over episode: %.4f\" % (float(train_acc),))\n",
        "\n",
        "                    # Reset training metrics at the end of each episode\n",
        "                    train_acc_metric.reset_states()\n",
        "                    \n",
        "                    CR.append(np.squeeze(np.sum(np.array(rewards))))\n",
        "\n",
        "                    env.close()\n",
        "                    if (episode%log_interval==0):\n",
        "                      show_video()\n",
        "                      output_dir = os.path.join(os.getcwd(), \"output\")\n",
        "                      if not os.path.exists(output_dir): os.mkdir(output_dir)\n",
        "                      prediction_network.save(os.path.join(output_dir,\"model-{}.h5\".format(episode/log_interval)))\n",
        "                      files.download(os.path.join(output_dir,\"model-{}.h5\".format(episode/log_interval)))\n",
        "                      plot(CR,episode+1)\n",
        "                    print(\"Episode {} finished after {} timesteps\".format(episode+1, time_step+1))\n",
        "                    print(\"{}s taken to finish this episode\".format(time.time() - start_time))\n",
        "                    break"
      ],
      "id": "771b5d7a",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "901e503d"
      },
      "source": [
        ""
      ],
      "id": "901e503d",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe8fd3b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "7befa86d-7560-4179-c714-1c387f8ec66e"
      },
      "source": [
        "learning_rate = 2.5e-3\n",
        "\n",
        "log_interval = 100\n",
        "\n",
        "initial_collect_steps = 200\n",
        "replay_buffer_max_length = 50000\n",
        "\n",
        "gamma = 0.99\n",
        "c = 10 # not sure\n",
        "eps = 0.00001\n",
        "batch_size = 32\n",
        "N_episodes = 12000\n",
        "\n",
        "initialization(input_shape,classes,initial_collect_steps,replay_buffer_max_length)\n",
        "experiment(N_episodes, gamma, learning_rate, c, batch_size,eps,log_interval)\n"
      ],
      "id": "fe8fd3b3",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time_step:1\n",
            "Time_step:2\n",
            "Time_step:3\n",
            "Time_step:4\n",
            "Time_step:5\n",
            "Time_step:6\n",
            "Time_step:7\n",
            "Time_step:8\n",
            "Time_step:9\n",
            "Time_step:10\n",
            "Time_step:11\n",
            "Time_step:12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-1eb7847b570f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0minitialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_collect_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplay_buffer_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-845c39b03a53>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(N_episodes, gamma, learning_rate, c, batch_size, eps, log_interval)\u001b[0m\n\u001b[1;32m     41\u001b[0m                         \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                         \u001b[0mQ_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                         \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mQ_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m    420\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 421\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    977\u001b[0m         np_arrays.ndarray, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m    867\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       expand_composites=expand_composites)\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m   \"\"\"\n\u001b[0;32m--> 755\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    617\u001b[0m         .format(truncate(flat_sequence, 100), type(flat_sequence)))\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m       raise ValueError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cff9431"
      },
      "source": [
        "\n"
      ],
      "id": "0cff9431",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe9NoHewSaBg"
      },
      "source": [
        "\n"
      ],
      "id": "pe9NoHewSaBg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SCDbmJZSdDP"
      },
      "source": [
        ""
      ],
      "id": "4SCDbmJZSdDP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBV3q32MSfRl"
      },
      "source": [
        " "
      ],
      "id": "GBV3q32MSfRl",
      "execution_count": null,
      "outputs": []
    }
  ]
}